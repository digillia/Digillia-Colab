{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM - Grands Modèles de Langage\n",
    "\n",
    "Les [transformers](https://arxiv.org/abs/1706.03762) ont changé les paradigmes du traitement du langage naturel. Il existe de nombreux modèles anglais et multilingues, mais peu de modèles français, l'inconvénient des modèles multilingues étant principalement leur taille, et accessoirement les faiblesses de la part du corpus d'entrainement dédiée au français. Nous avons donc souhaité rendre ici hommage aux rares modèles dédiés au français, que sont [Camembert](https://huggingface.co/almanach), [Croissant](https://huggingface.co/croissantllm), [Flaubert](https://huggingface.co/flaubert), [Vigogne](https://huggingface.co/bofenghuang), et bientôt Lucie.\n",
    "\n",
    "Les modèles multilangues comme [Gemini](../tools/gemini.ipynb) et [OpenAI](../tools/openai.ipynb), offrent des résultats supérieurs aux modèles entraînés en français seulement. Il peut néanmoins être intéressant d'utiliser ces petits modèles français quand les ressources computationnelles (CPU, GPU, RAM, VRAM) sont limitées et/ou quand l'accès à un modèle SaaS par des API de type RESTful n'est pas adapté.\n",
    "\n",
    "[![Index](https://img.shields.io/badge/Index-blue)](../index.ipynb)\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/digillia/Digillia-Colab/blob/main/algorithms/large-language-models.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Supprimer les commentaires pour installer (requirements.txt)\n",
    "# !pip3 install -q -U torch\n",
    "# !pip3 install -q -U transformers\n",
    "\n",
    "# À installer dans tous les cas pour Google Colab et Github\n",
    "if 'google.colab' in sys.modules or 'CI' in os.environ:\n",
    "    #!pip3 install -q -U accelerate # requis par Croissant (device_map=\"auto\")\n",
    "    !pip3 install -q -U sentencepiece # requis par Camembert\n",
    "    !pip3 install -q -U sacremoses # requis par Flaubert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camembert\n",
    "camembert_name = \"camembert/camembert-base\"\n",
    "# Croissant\n",
    "# croissant_name = \"croissantllm/CroissantLLMBase\"\n",
    "# Flaubert\n",
    "flaubert_name = \"flaubert/flaubert_base_cased\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, CamembertTokenizer, FlaubertTokenizer\n",
    "\n",
    "# Camembert\n",
    "camembert_tokenizer = CamembertTokenizer.from_pretrained(camembert_name)\n",
    "# Croissant\n",
    "# croissant_tokenizer = AutoTokenizer.from_pretrained(croissant_name)\n",
    "# Flaubert\n",
    "flaubert_tokenizer = FlaubertTokenizer.from_pretrained(flaubert_name, do_lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(camembert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(croissant_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flaubert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_vocab(name='<s>', tokenizer=camembert_tokenizer):\n",
    "    vocab = tokenizer.get_vocab()\n",
    "    try:\n",
    "        id = vocab[name]\n",
    "        print(f\"{name} est dans le vocabulaire de {tokenizer.name_or_path}: {id}\")\n",
    "    except KeyError:\n",
    "        print(f\"{name} n'est pas dans le vocabulaire de {tokenizer.name_or_path}\")\n",
    "\n",
    "# Camembert\n",
    "check_vocab()\n",
    "check_vocab('chat')\n",
    "check_vocab('chien')\n",
    "check_vocab('balle')\n",
    "print()\n",
    "# Croissant\n",
    "# check_vocab(tokenizer=croissant_tokenizer)\n",
    "# check_vocab('chat', croissant_tokenizer)\n",
    "# check_vocab('chien', croissant_tokenizer)\n",
    "# check_vocab('balle', croissant_tokenizer)\n",
    "# print()\n",
    "# Flaubert\n",
    "check_vocab(tokenizer=flaubert_tokenizer)\n",
    "check_vocab('chat', flaubert_tokenizer)\n",
    "check_vocab('chien', flaubert_tokenizer)\n",
    "check_vocab('balle', flaubert_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, CamembertModel, FlaubertModel\n",
    "\n",
    "# Camembert\n",
    "camembert_model = CamembertModel.from_pretrained(camembert_name)\n",
    "# Croissant\n",
    "# croissant_model = AutoModelForCausalLM.from_pretrained(croissant_name, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "# Flaubert\n",
    "flaubert_model = FlaubertModel.from_pretrained(flaubert_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, CamembertModel, FlaubertModel\n",
    "\n",
    "# Camembert\n",
    "camembert_model = CamembertModel.from_pretrained(camembert_name)\n",
    "# Croissant\n",
    "# croissant_model = AutoModelForCausalLM.from_pretrained(croissant_name, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "# Flaubert\n",
    "flaubert_model = FlaubertModel.from_pretrained(flaubert_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "nlp_fill_camembert = pipeline('fill-mask', model=camembert_name, top_k=10)\n",
    "# nlp_fill_croissant = pipeline('fill-mask', model=croissant_name, top_k=10)\n",
    "nlp_fill_flaubert = pipeline('fill-mask', model=flaubert_name, top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO https://medium.com/@xiaoouwang/playing-with-camembert-and-flaubert-8c5d40e502a7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = tokenizer(\"I am so tired I could sleep right now. -> Je suis si fatigué que je pourrais m'endormir maintenant.\\nHe is heading to the market. -> Il va au marché.\\nWe are running on the beach. ->\", return_tensors=\"pt\").to(model.device)\n",
    "# tokens = model.generate(**inputs, max_length=100, do_sample=True, top_p=0.95, top_k=60, temperature=0.3)\n",
    "# print(tokenizer.decode(tokens[0]))\n",
    "\n",
    "# remove bos token\n",
    "# inputs = tokenizer(\"Capitales: France -> Paris, Italie -> Rome, Allemagne -> Berlin, Espagne ->\", return_tensors=\"pt\", add_special_tokens=True).to(model.device)\n",
    "# tokens = model.generate(**inputs, max_length=100, do_sample=True, top_p=0.95, top_k=60)\n",
    "# print(tokenizer.decode(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour supprimer les modèles du cache\n",
    "# !pip3 install -q -U \"huggingface_hub[cli]\"\n",
    "# !huggingface-cli scan-cache\n",
    "# !huggingface-cli delete-cache"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
