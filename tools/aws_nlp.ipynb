{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS NLP\n",
    "\n",
    "[![Index](https://img.shields.io/badge/Index-blue)](../index.ipynb)\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/digillia/Digillia-Colab/blob/main/tools/aws_nlp.ipynb)\n",
    "\n",
    "\n",
    "Docs:\n",
    "- https://aws.amazon.com/ai/services/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Supprimer les commentaires pour installer (requirements.txt)\n",
    "\n",
    "# Ã€ installer dans tous les cas pour Google Colab et Github\n",
    "if ('google.colab' in sys.modules) or ('CI' in os.environ):\n",
    "    !pip3 install -q -U boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import userdata\n",
    "    os.environ['AWS_ACCESS_KEY_ID'] = userdata.get('AWS_ACCESS_KEY_ID')\n",
    "    os.environ['AWS_SECRET_ACCESS_KEY'] = userdata.get('AWS_SECRET_ACCESS_KEY')\n",
    "    os.environ['AWS_DEFAULT_REGION'] = userdata.get('AWS_DEFAULT_REGION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les variables python sont accessibles depuis les commandes shell\n",
    "work_directory = './aws_nlp'\n",
    "\n",
    "!mkdir -p $work_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ID: amazon.titan-tg1-large\n",
      "Model ID: amazon.titan-image-generator-v1:0\n",
      "Model ID: amazon.titan-image-generator-v1\n",
      "Model ID: amazon.titan-image-generator-v2:0\n",
      "Model ID: amazon.titan-text-premier-v1:0\n",
      "Model ID: amazon.nova-pro-v1:0:300k\n",
      "Model ID: amazon.nova-pro-v1:0\n",
      "Model ID: amazon.nova-lite-v1:0:300k\n",
      "Model ID: amazon.nova-lite-v1:0\n",
      "Model ID: amazon.nova-canvas-v1:0\n",
      "Model ID: amazon.nova-reel-v1:0\n",
      "Model ID: amazon.nova-micro-v1:0:128k\n",
      "Model ID: amazon.nova-micro-v1:0\n",
      "Model ID: amazon.titan-embed-g1-text-02\n",
      "Model ID: amazon.titan-text-lite-v1:0:4k\n",
      "Model ID: amazon.titan-text-lite-v1\n",
      "Model ID: amazon.titan-text-express-v1:0:8k\n",
      "Model ID: amazon.titan-text-express-v1\n",
      "Model ID: amazon.titan-embed-text-v1:2:8k\n",
      "Model ID: amazon.titan-embed-text-v1\n",
      "Model ID: amazon.titan-embed-text-v2:0:8k\n",
      "Model ID: amazon.titan-embed-text-v2:0\n",
      "Model ID: amazon.titan-embed-image-v1:0\n",
      "Model ID: amazon.titan-embed-image-v1\n",
      "Model ID: stability.stable-diffusion-xl-v1:0\n",
      "Model ID: stability.stable-diffusion-xl-v1\n",
      "Model ID: ai21.j2-grande-instruct\n",
      "Model ID: ai21.j2-jumbo-instruct\n",
      "Model ID: ai21.j2-mid\n",
      "Model ID: ai21.j2-mid-v1\n",
      "Model ID: ai21.j2-ultra\n",
      "Model ID: ai21.j2-ultra-v1:0:8k\n",
      "Model ID: ai21.j2-ultra-v1\n",
      "Model ID: ai21.jamba-instruct-v1:0\n",
      "Model ID: ai21.jamba-1-5-large-v1:0\n",
      "Model ID: ai21.jamba-1-5-mini-v1:0\n",
      "Model ID: anthropic.claude-instant-v1:2:100k\n",
      "Model ID: anthropic.claude-instant-v1\n",
      "Model ID: anthropic.claude-v2:0:18k\n",
      "Model ID: anthropic.claude-v2:0:100k\n",
      "Model ID: anthropic.claude-v2:1:18k\n",
      "Model ID: anthropic.claude-v2:1:200k\n",
      "Model ID: anthropic.claude-v2:1\n",
      "Model ID: anthropic.claude-v2\n",
      "Model ID: anthropic.claude-3-sonnet-20240229-v1:0:28k\n",
      "Model ID: anthropic.claude-3-sonnet-20240229-v1:0:200k\n",
      "Model ID: anthropic.claude-3-sonnet-20240229-v1:0\n",
      "Model ID: anthropic.claude-3-haiku-20240307-v1:0:48k\n",
      "Model ID: anthropic.claude-3-haiku-20240307-v1:0:200k\n",
      "Model ID: anthropic.claude-3-haiku-20240307-v1:0\n",
      "Model ID: anthropic.claude-3-opus-20240229-v1:0:12k\n",
      "Model ID: anthropic.claude-3-opus-20240229-v1:0:28k\n",
      "Model ID: anthropic.claude-3-opus-20240229-v1:0:200k\n",
      "Model ID: anthropic.claude-3-opus-20240229-v1:0\n",
      "Model ID: anthropic.claude-3-5-sonnet-20240620-v1:0\n",
      "Model ID: anthropic.claude-3-5-sonnet-20241022-v2:0\n",
      "Model ID: anthropic.claude-3-5-haiku-20241022-v1:0\n",
      "Model ID: cohere.command-text-v14:7:4k\n",
      "Model ID: cohere.command-text-v14\n",
      "Model ID: cohere.command-r-v1:0\n",
      "Model ID: cohere.command-r-plus-v1:0\n",
      "Model ID: cohere.command-light-text-v14:7:4k\n",
      "Model ID: cohere.command-light-text-v14\n",
      "Model ID: cohere.embed-english-v3:0:512\n",
      "Model ID: cohere.embed-english-v3\n",
      "Model ID: cohere.embed-multilingual-v3:0:512\n",
      "Model ID: cohere.embed-multilingual-v3\n",
      "Model ID: meta.llama3-8b-instruct-v1:0\n",
      "Model ID: meta.llama3-70b-instruct-v1:0\n",
      "Model ID: meta.llama3-1-8b-instruct-v1:0\n",
      "Model ID: meta.llama3-1-70b-instruct-v1:0\n",
      "Model ID: meta.llama3-2-11b-instruct-v1:0\n",
      "Model ID: meta.llama3-2-90b-instruct-v1:0\n",
      "Model ID: meta.llama3-2-1b-instruct-v1:0\n",
      "Model ID: meta.llama3-2-3b-instruct-v1:0\n",
      "Model ID: mistral.mistral-7b-instruct-v0:2\n",
      "Model ID: mistral.mixtral-8x7b-instruct-v0:1\n",
      "Model ID: mistral.mistral-large-2402-v1:0\n",
      "Model ID: mistral.mistral-small-2402-v1:0\n"
     ]
    }
   ],
   "source": [
    "bedrock_client = boto3.client('bedrock')\n",
    "def list_available_models():\n",
    "    try:\n",
    "        response = bedrock_client.list_foundation_models()\n",
    "        for model in response['modelSummaries']:\n",
    "            print(f\"Model ID: {model['modelId']}\")\n",
    "    except ClientError as error:\n",
    "        print(f\"Error listing models: {error}\")\n",
    "\n",
    "list_available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "usage: aws [options] <command> <subcommand> [<subcommand> ...] [parameters]\n",
      "To see help text, you can run:\n",
      "\n",
      "  aws help\n",
      "  aws <command> help\n",
      "  aws <command> <subcommand> help\n",
      "\n",
      "aws: error: argument operation: Invalid choice, valid choices are:\n",
      "\n",
      "batch-delete-evaluation-job              | create-evaluation-job                   \n",
      "create-guardrail                         | create-guardrail-version                \n",
      "create-inference-profile                 | create-marketplace-model-endpoint       \n",
      "create-model-copy-job                    | create-model-customization-job          \n",
      "create-model-import-job                  | create-model-invocation-job             \n",
      "create-provisioned-model-throughput      | delete-custom-model                     \n",
      "delete-guardrail                         | delete-imported-model                   \n",
      "delete-inference-profile                 | delete-marketplace-model-endpoint       \n",
      "delete-model-invocation-logging-configuration | delete-provisioned-model-throughput     \n",
      "deregister-marketplace-model-endpoint    | get-custom-model                        \n",
      "get-evaluation-job                       | get-foundation-model                    \n",
      "get-guardrail                            | get-imported-model                      \n",
      "get-inference-profile                    | get-marketplace-model-endpoint          \n",
      "get-model-copy-job                       | get-model-customization-job             \n",
      "get-model-import-job                     | get-model-invocation-job                \n",
      "get-model-invocation-logging-configuration | get-prompt-router                       \n",
      "get-provisioned-model-throughput         | list-custom-models                      \n",
      "list-evaluation-jobs                     | list-foundation-models                  \n",
      "list-guardrails                          | list-imported-models                    \n",
      "list-inference-profiles                  | list-marketplace-model-endpoints        \n",
      "list-model-copy-jobs                     | list-model-customization-jobs           \n",
      "list-model-import-jobs                   | list-model-invocation-jobs              \n",
      "list-prompt-routers                      | list-provisioned-model-throughputs      \n",
      "list-tags-for-resource                   | put-model-invocation-logging-configuration\n",
      "register-marketplace-model-endpoint      | stop-evaluation-job                     \n",
      "stop-model-customization-job             | stop-model-invocation-job               \n",
      "tag-resource                             | untag-resource                          \n",
      "update-guardrail                         | update-marketplace-model-endpoint       \n",
      "update-provisioned-model-throughput      | help                                    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_id='amazon.nova-micro-v1:0'\n",
    "\n",
    "# Grant access to the model\n",
    "#!aws configure add-model --service-model file://bedrock-2023-04-20.normal.json\n",
    "!aws bedrock grant-model-access --model-ids $model_id --principal-arn arn:aws:iam::$(aws sts get-caller-identity --query Account --output text):root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating text: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n"
     ]
    }
   ],
   "source": [
    "bedrock_runtime = boto3.client('bedrock-runtime')\n",
    "\n",
    "def generate_text(prompt):\n",
    "    # Model ID for Amazon Titan Text Express\n",
    "    model_id = \"amazon.titan-text-express-v1\"\n",
    "    \n",
    "    try:\n",
    "        # Format the request payload for Titan model\n",
    "        request_body = {\n",
    "            \"inputText\": prompt,\n",
    "            \"textGenerationConfig\": {\n",
    "                \"maxTokenCount\": 512,\n",
    "                \"temperature\": 0.7,\n",
    "                \"topP\": 0.9,\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Convert dictionary to JSON string\n",
    "        body = json.dumps(request_body)\n",
    "        \n",
    "        # Call the model\n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            modelId=model_id,\n",
    "            body=body\n",
    "        )\n",
    "        \n",
    "        # Parse the response\n",
    "        response_body = json.loads(response.get('body').read())\n",
    "        \n",
    "        # Extract the generated text\n",
    "        return response_body['results'][0]['outputText']\n",
    "    \n",
    "    except ClientError as error:\n",
    "        print(f\"Error generating text: {error}\")\n",
    "        return None\n",
    "\n",
    "prompt = \"Write a short poem about artificial intelligence.\"\n",
    "result = generate_text(prompt)\n",
    "if result:\n",
    "    print(\"Generated text:\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParamValidationError",
     "evalue": "Parameter validation failed:\nMissing required parameter in input: \"jobName\"\nMissing required parameter in input: \"roleArn\"\nMissing required parameter in input: \"inputDataConfig\"\nMissing required parameter in input: \"outputDataConfig\"\nUnknown parameter in input: \"body\", must be one of: jobName, roleArn, clientRequestToken, modelId, inputDataConfig, outputDataConfig, vpcConfig, timeoutDurationInHours, tags\nUnknown parameter in input: \"contentType\", must be one of: jobName, roleArn, clientRequestToken, modelId, inputDataConfig, outputDataConfig, vpcConfig, timeoutDurationInHours, tags",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParamValidationError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 12\u001b[0m\n\u001b[1;32m      7\u001b[0m request_body \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps({\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputText\u001b[39m\u001b[38;5;124m\"\u001b[39m: input_text\n\u001b[1;32m      9\u001b[0m })\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Create an async invocation job\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mbedrock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model_invocation_job\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodelId\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontentType\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mapplication/json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Get the job ID\u001b[39;00m\n\u001b[1;32m     19\u001b[0m job_id \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjobId\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/Projects/Digillia/Digillia-Colab/.venv/lib/python3.12/site-packages/botocore/client.py:569\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m     )\n\u001b[1;32m    568\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/Digillia/Digillia-Colab/.venv/lib/python3.12/site-packages/botocore/client.py:980\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m properties:\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;66;03m# Pass arbitrary endpoint info with the Request\u001b[39;00m\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;66;03m# for use during construction.\u001b[39;00m\n\u001b[1;32m    979\u001b[0m     request_context[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mendpoint_properties\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m properties\n\u001b[0;32m--> 980\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_to_request_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperation_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperation_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    987\u001b[0m resolve_checksum_context(request_dict, operation_model, api_params)\n\u001b[1;32m    989\u001b[0m service_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_service_model\u001b[38;5;241m.\u001b[39mservice_id\u001b[38;5;241m.\u001b[39mhyphenize()\n",
      "File \u001b[0;32m~/Projects/Digillia/Digillia-Colab/.venv/lib/python3.12/site-packages/botocore/client.py:1047\u001b[0m, in \u001b[0;36mBaseClient._convert_to_request_dict\u001b[0;34m(self, api_params, operation_model, endpoint_url, context, headers, set_user_agent_header)\u001b[0m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convert_to_request_dict\u001b[39m(\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1040\u001b[0m     api_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     set_user_agent_header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1046\u001b[0m ):\n\u001b[0;32m-> 1047\u001b[0m     request_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serializer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserialize_to_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_model\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_config\u001b[38;5;241m.\u001b[39minject_host_prefix:\n\u001b[1;32m   1051\u001b[0m         request_dict\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhost_prefix\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/Projects/Digillia/Digillia-Colab/.venv/lib/python3.12/site-packages/botocore/validate.py:381\u001b[0m, in \u001b[0;36mParamValidationDecorator.serialize_to_request\u001b[0;34m(self, parameters, operation_model)\u001b[0m\n\u001b[1;32m    377\u001b[0m     report \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param_validator\u001b[38;5;241m.\u001b[39mvalidate(\n\u001b[1;32m    378\u001b[0m         parameters, operation_model\u001b[38;5;241m.\u001b[39minput_shape\n\u001b[1;32m    379\u001b[0m     )\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m report\u001b[38;5;241m.\u001b[39mhas_errors():\n\u001b[0;32m--> 381\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ParamValidationError(report\u001b[38;5;241m=\u001b[39mreport\u001b[38;5;241m.\u001b[39mgenerate_report())\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serializer\u001b[38;5;241m.\u001b[39mserialize_to_request(\n\u001b[1;32m    383\u001b[0m     parameters, operation_model\n\u001b[1;32m    384\u001b[0m )\n",
      "\u001b[0;31mParamValidationError\u001b[0m: Parameter validation failed:\nMissing required parameter in input: \"jobName\"\nMissing required parameter in input: \"roleArn\"\nMissing required parameter in input: \"inputDataConfig\"\nMissing required parameter in input: \"outputDataConfig\"\nUnknown parameter in input: \"body\", must be one of: jobName, roleArn, clientRequestToken, modelId, inputDataConfig, outputDataConfig, vpcConfig, timeoutDurationInHours, tags\nUnknown parameter in input: \"contentType\", must be one of: jobName, roleArn, clientRequestToken, modelId, inputDataConfig, outputDataConfig, vpcConfig, timeoutDurationInHours, tags"
     ]
    }
   ],
   "source": [
    "# Create an Amazon Bedrock client\n",
    "bedrock = boto3.client('bedrock')\n",
    "model_id = 'amazon.titan-1.0'\n",
    "input_text = \"Once upon a time in a faraway kingdom, there was a dragon.\"\n",
    "\n",
    "# Prepare request body as JSON string\n",
    "request_body = json.dumps({\n",
    "    \"inputText\": input_text\n",
    "})\n",
    "\n",
    "# Create an async invocation job\n",
    "response = bedrock.create_model_invocation_job(\n",
    "    modelId=model_id,\n",
    "    body=request_body,\n",
    "    contentType='application/json'\n",
    ")\n",
    "\n",
    "# Get the job ID\n",
    "job_id = response['jobId']\n",
    "\n",
    "# Wait for job completion\n",
    "waiter = bedrock.get_waiter('model_invocation_job_completed')\n",
    "waiter.wait(jobId=job_id)\n",
    "\n",
    "# Get the results\n",
    "result = bedrock.get_model_invocation_job(jobId=job_id)\n",
    "response_body = json.loads(result['responseBody'])\n",
    "print(\"Model response:\")\n",
    "print(response_body['results'][0]['outputText'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sentiment': 'POSITIVE', 'SentimentScore': {'Positive': 0.99946528673172, 'Negative': 3.780597762670368e-05, 'Neutral': 0.000492282269988209, 'Mixed': 4.617959802999394e-06}, 'ResponseMetadata': {'RequestId': '1c2f0875-4324-4a7a-a855-0ca8680acde5', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '1c2f0875-4324-4a7a-a855-0ca8680acde5', 'content-type': 'application/x-amz-json-1.1', 'content-length': '162', 'date': 'Fri, 13 Dec 2024 20:15:28 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "comprehend_client = boto3.client('comprehend')\n",
    "text = 'J\\'aime aller au cinÃ©ma.' \n",
    "sentiment = comprehend_client.detect_sentiment(Text=text, LanguageCode='fr')\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "polly_client = boto3.client('polly')\n",
    "text = 'J\\'aime aller au cinÃ©ma.'\n",
    "# Check voices at https://docs.aws.amazon.com/polly/latest/dg/available-voices.html\n",
    "result = polly_client.synthesize_speech(Text=text, OutputFormat='mp3', VoiceId='Lea', LanguageCode='fr-FR')\n",
    "audio = result['AudioStream'].read()\n",
    "with open(f'{work_directory}/audio.mp3', 'wb') as file:\n",
    "    file.write(audio)\n",
    "Audio(filename=f'{work_directory}/audio.mp3', autoplay=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Initialize clients\n",
    "s3_client = boto3.client('s3')\n",
    "transcribe_client = boto3.client('transcribe')\n",
    "\n",
    "# File details\n",
    "local_file_path = \"C:/Users/YourUsername/Desktop/audio.mp3\"  # Update with the path to your MP3 file\n",
    "bucket_name = \"your-s3-bucket-name\"  # Replace with your S3 bucket name\n",
    "s3_object_name = \"audio/audio.mp3\"  # Path and name for the file in S3\n",
    "transcription_job_name = \"my-transcription-job\"  # Unique name for your transcription job\n",
    "language_code = 'fr-FR'\n",
    "\n",
    "# Chargement du fichier dans s3\n",
    "def upload_file_to_s3(local_path, bucket, s3_path):\n",
    "    try:\n",
    "        s3_client.upload_file(local_path, bucket, s3_path)\n",
    "        print(f\"File uploaded to S3: s3://{bucket}/{s3_path}\")\n",
    "        return f\"s3://{bucket}/{s3_path}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading file: {e}\")\n",
    "        return None\n",
    "\n",
    "s3_uri = upload_file_to_s3(local_file_path, bucket_name, s3_object_name)\n",
    "if not s3_uri:\n",
    "    exit()\n",
    "\n",
    "# Step 2: Start transcription job\n",
    "def start_transcription(s3_uri, job_name, language):\n",
    "    try:\n",
    "        transcribe.start_transcription_job(\n",
    "            TranscriptionJobName=job_name,\n",
    "            Media={'MediaFileUri': s3_uri},\n",
    "            MediaFormat='mp3',  # Update if your file has a different format\n",
    "            LanguageCode=language,\n",
    "            OutputBucketName=bucket_name  # Optional: store the result in S3\n",
    "        )\n",
    "        print(f\"Transcription job '{job_name}' started.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error starting transcription job: {e}\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "if not start_transcription(s3_uri, transcription_job_name, language_code):\n",
    "    exit()\n",
    "\n",
    "# Step 3: Wait for transcription job to complete\n",
    "def wait_for_transcription(job_name):\n",
    "    while True:\n",
    "        status = transcribe.get_transcription_job(TranscriptionJobName=job_name)\n",
    "        job_status = status['TranscriptionJob']['TranscriptionJobStatus']\n",
    "        if job_status in ['COMPLETED', 'FAILED']:\n",
    "            print(f\"Transcription job status: {job_status}\")\n",
    "            if job_status == 'COMPLETED':\n",
    "                return status['TranscriptionJob']['Transcript']['TranscriptFileUri']\n",
    "            else:\n",
    "                print(f\"Transcription failed: {status}\")\n",
    "                return None\n",
    "        print(\"Waiting for transcription to complete...\")\n",
    "        time.sleep(10)\n",
    "\n",
    "transcript_uri = wait_for_transcription(transcription_job_name)\n",
    "\n",
    "# Step 4: Retrieve transcription result\n",
    "if transcript_uri:\n",
    "    print(f\"Transcription completed. Transcript URL: {transcript_uri}\")\n",
    "    # Optional: Download and display the transcription\n",
    "    import requests\n",
    "    response = requests.get(transcript_uri)\n",
    "    if response.status_code == 200:\n",
    "        transcript = response.json()['results']['transcripts'][0]['transcript']\n",
    "        print(f\"Transcript: {transcript}\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve transcript from {transcript_uri}\")\n",
    "else:\n",
    "    print(\"Transcription failed or job did not complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MÃ©nage\n",
    "!rm -rf $work_directory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
