{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microsoft PromptFlow\n",
    "\n",
    "Comme [LangChain](./langchain.ipynb) et [LlamaIndex](./llamaindex.ipynb), Microsoft PromptFlow founit un framework pour la création de pipelines RAG, mais en plus PromptFlow fournit une architecture de déploiement et des outils de trace et d'évaluation de type LangSmith.\n",
    "\n",
    "[![Index](https://img.shields.io/badge/Index-blue)](../index.ipynb)\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/digillia/Digillia-Colab/blob/main/tools/promptflow.ipynb)\n",
    "\n",
    "Docs:\n",
    "- https://github.com/microsoft/promptflow\n",
    "- https://microsoft.github.io/promptflow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Supprimer les commentaires pour installer (requirements.txt)\n",
    "# !pip3 install -q -U python-dotenv\n",
    "# !pip3 install -q -U \"promptflow[executable]\"\n",
    "\n",
    "# À installer dans tous les cas pour Google Colab et Github\n",
    "if 'google.colab' in sys.modules or 'CI' in os.environ:\n",
    "    !pip3 install -q -U openai\n",
    "    !pip3 install -q -U promptflow\n",
    "    !pip3 install -q -U promptflow-tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considérer éventuellement l'installation de l'extension pour VS Code:\n",
    "- https://marketplace.visualstudio.com/items?itemName=prompt-flow.prompt-flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les variables python sont accessibles depuis les commandes shell\n",
    "flow_name = 'promptflow'\n",
    "work_directory = f'./{flow_name}'\n",
    "\n",
    "#!mkdir -p $work_directory # Inutile, le répertoire est créé par `pf flow init` ci-après"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'un flux standard basique\n",
    "\n",
    "Un flux standard basique comprend essentiellement un modèle de prompt au format `.jinja2`, un fichier de code python `.py`, et un fichier `flow.dag.yaml`décrivant le DAG (Directed Acyclic Graph) du flux, qui dans ce cas consiste à fusionner le texte d'entrée avec le modèle pour produire un prompt qui est passé à la fonction du fichier de code python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jlchereau/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "Creating flow from scratch...\n",
      "Creating hello.py...\n",
      "Creating data.jsonl...\n",
      "Creating .promptflow folder...\n",
      "Creating flow.dag.yaml...\n",
      "Creating hello.jinja2...\n",
      "Creating /Users/jlchereau/WebstormProjects/Digillia/Digillia-Colab/tools/promptflow/requirements.txt...\n",
      "Creating /Users/jlchereau/WebstormProjects/Digillia/Digillia-Colab/tools/promptflow/.gitignore...\n",
      "Done. Created standard flow folder: /Users/jlchereau/WebstormProjects/Digillia/Digillia-Colab/tools/promptflow.\n",
      "You can execute this command to test the flow, pf flow test --flow promptflow --input promptflow/data.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Création du répertoire et des fichiers du flux\n",
    "!pf flow init --flow $flow_name --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jlchereau/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "Starting prompt flow service...\n",
      "Start prompt flow service on port 51053, version: 1.9.0.\n",
      "You can stop the prompt flow service with the following command:'\u001b[1mpf service stop\u001b[0m'.\n",
      "Alternatively, if no requests are made within 1 hours, it will automatically stop.\n",
      "You can view the traces from local: http://localhost:51053/v1.0/ui/traces/?#collection=promptflow\n",
      "2024-04-25 19:38:40 +0200   15730 execution.flow     INFO     Start executing nodes in thread pool mode.\n",
      "2024-04-25 19:38:40 +0200   15730 execution.flow     INFO     Start to run 2 nodes with concurrency level 16.\n",
      "2024-04-25 19:38:40 +0200   15730 execution.flow     INFO     Executing node hello_prompt. node run id: 208aefba-84dd-4955-982a-acb72e7c7cc6_hello_prompt_0\n",
      "2024-04-25 19:38:40 +0200   15730 execution.flow     INFO     Node hello_prompt completes.\n",
      "2024-04-25 19:38:40 +0200   15730 execution.flow     INFO     Executing node echo_my_prompt. node run id: 208aefba-84dd-4955-982a-acb72e7c7cc6_echo_my_prompt_0\n",
      "2024-04-25 19:38:40 +0200   15730 execution.flow     INFO     Node echo_my_prompt completes.\n",
      "{\n",
      "    \"output_prompt\": \"Prompt: Write a simple Hello World! program that displays the greeting message.\\n\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Exécution du flux qui retourne le prompt résultant de la fusion du modèle jinja2 et du texte dans `data.jsonl`.\n",
    "!pf flow test --flow $flow_name --input $work_directory/data.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intégration d'un LLM (OpenAI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement de la Clé pour OpenAI\n",
    "\n",
    "Il vous faut obtenir d'Open AI une clé pour exécuter ce bloc-note Jupyter. Vous pouvez consulter [Where do I find my API key?](https://help.openai.com/en/articles/4936850-where-do-i-find-my-api-key). Ensuite, le chargement se fait soit à partir de l'environnement (fichier `.env`), soit à partir des secrets de Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import userdata\n",
    "    os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
    "else:\n",
    "    from dotenv import load_dotenv, find_dotenv\n",
    "    _ = load_dotenv(find_dotenv()) # lire le fichier .env local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changement de modèle de prompt\n",
    "\n",
    "Créons un prompt pour faire de l'analyse de sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./promptflow/hello.jinja2\n"
     ]
    }
   ],
   "source": [
    "%%writefile $work_directory/hello.jinja2\n",
    "Fais l'analyse de sentiment du texte délimité par un triple guillemet simple.\n",
    "Réponds en un seul mot: soit \"positif\", soit \"négatif\", soit \"neutre\".\n",
    "Réponds \"neutre\" si tu ne sais pas. Réponds \"négatif\" si le langage est toxique.\n",
    "\n",
    "Texte à évaluer: '''{{text}}'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changement de la fonction de traitement du prompt\n",
    "\n",
    "Créons une fonction qui passe le prompt à l'API d'OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./promptflow/hello.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $work_directory/hello.py\n",
    "import os\n",
    "import sys\n",
    "from promptflow.core import tool\n",
    "from openai import OpenAI\n",
    "\n",
    "@tool\n",
    "def my_python_tool(input1: str) -> str:\n",
    "    client = OpenAI() # (api_key=os.environ['OPENAI_API_KEY'])\n",
    "    completion = client.chat.completions.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=[{'role': 'user', 'content': input1}]\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changement du fichier de données entrantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./promptflow/data.jsonl\n"
     ]
    }
   ],
   "source": [
    "%%writefile $work_directory/data.jsonl\n",
    "{\"text\": \"Quelle belle voiture!\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jlchereau/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "Prompt flow service has started...\n",
      "You can view the traces from local: http://localhost:51053/v1.0/ui/traces/?#collection=promptflow\n",
      "2024-04-25 19:38:42 +0200   15750 execution.flow     INFO     Start executing nodes in thread pool mode.\n",
      "2024-04-25 19:38:42 +0200   15750 execution.flow     INFO     Start to run 2 nodes with concurrency level 16.\n",
      "2024-04-25 19:38:42 +0200   15750 execution.flow     INFO     Executing node hello_prompt. node run id: e2c490d5-6e24-443f-8519-ff3b8d3bcc74_hello_prompt_0\n",
      "2024-04-25 19:38:42 +0200   15750 execution.flow     INFO     Node hello_prompt completes.\n",
      "2024-04-25 19:38:42 +0200   15750 execution.flow     INFO     Executing node echo_my_prompt. node run id: e2c490d5-6e24-443f-8519-ff3b8d3bcc74_echo_my_prompt_0\n",
      "2024-04-25 19:38:43 +0200   15750 execution.flow     INFO     Node echo_my_prompt completes.\n",
      "{\n",
      "    \"output_prompt\": \"positif\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Exécution du flux qui retourne le sentiment ressortisant du texte dans `data.jsonl`.\n",
    "!pf flow test --flow $flow_name --input $work_directory/data.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jlchereau/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "[2024-04-25 19:38:45,722][pfserving-app][INFO] - opentelemetry-instrumentation-flask is not installed, auto-instrumentation is not enabled.\n",
      "[2024-04-25 19:38:45,722][pfserving-app][INFO] - Static_folder: /Users/jlchereau/Library/Python/3.9/lib/python/site-packages/promptflow/core/_serving/static\n",
      "[2024-04-25 19:38:45,722][pfserving-app][INFO] - Project path: /Users/jlchereau/WebstormProjects/Digillia/Digillia-Colab/tools/promptflow\n",
      "[2024-04-25 19:38:45,727][pfserving-app][INFO] - No connection string detected, app insight metric exporter is disabled.\n",
      "[2024-04-25 19:38:45,727][pfserving-app][INFO] - No connection string detected, app insight trace exporter is disabled.\n",
      "[2024-04-25 19:38:45,727][pfserving-app][WARNING] - No metric exporter enabled.\n",
      "[2024-04-25 19:38:45,727][pfserving-app][WARNING] - No trace exporter enabled.\n",
      "[2024-04-25 19:38:45,727][pfserving-app][INFO] - Init params: {}\n",
      "[2024-04-25 19:38:45,733][pfserving-app][INFO] - Promptflow executor starts initializing...\n",
      "[2024-04-25 19:38:45,742][flowinvoker][INFO] - Getting connections from pf client with provider from args: local...\n",
      "[2024-04-25 19:38:45,754][flowinvoker][INFO] - Promptflow get connections successfully. keys: dict_keys([])\n",
      "[2024-04-25 19:38:45,754][flowinvoker][INFO] - Promptflow executor starts initializing...\n",
      "[2024-04-25 19:38:45,770][flowinvoker][INFO] - Promptflow executor initiated successfully.\n",
      "[2024-04-25 19:38:45,770][pfserving-app][INFO] - Promptflow executor initializing succeed!\n",
      " * Serving Flask app 'promptflow.core._serving.app'\n",
      " * Debug mode: off\n",
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://localhost:8080\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug:127.0.0.1 - - [25/Apr/2024 19:38:46] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [25/Apr/2024 19:38:47] \"\u001b[36mGET /static/index.js HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [25/Apr/2024 19:38:47] \"\u001b[36mGET /static/index.js HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [25/Apr/2024 19:38:47] \"GET /swagger.json HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [25/Apr/2024 19:38:47] \"GET /swagger.json HTTP/1.1\" 200 -\n",
      "[2024-04-25 19:38:53,958][pfserving-app][INFO] - Start monitoring new request, request_id: None, client_request_id: None\n",
      "[2024-04-25 19:38:53,959][pfserving-app][INFO] - Start loading request data...\n",
      "[2024-04-25 19:38:53,963][flowinvoker][INFO] - Validating flow input with data {'text': 'hello'}\n",
      "[2024-04-25 19:38:53,963][flowinvoker][INFO] - Execute flow with data {'text': 'hello'}\n",
      "2024-04-25 19:38:53 +0200   15759 execution.flow     INFO     Start executing nodes in thread pool mode.\n",
      "2024-04-25 19:38:53 +0200   15759 execution.flow     INFO     Start to run 2 nodes with concurrency level 16.\n",
      "2024-04-25 19:38:53 +0200   15759 execution.flow     INFO     Executing node hello_prompt. node run id: 3b2ec663-a3fe-40c3-9401-5570015e2794_hello_prompt_4c00c181-fb94-4fab-9dd1-09e9eea27522\n",
      "2024-04-25 19:38:53 +0200   15759 execution.flow     INFO     Node hello_prompt completes.\n",
      "2024-04-25 19:38:53 +0200   15759 execution.flow     INFO     Executing node echo_my_prompt. node run id: 3b2ec663-a3fe-40c3-9401-5570015e2794_echo_my_prompt_eafec437-f268-4dbf-8df5-3a9105fe143a\n",
      "2024-04-25 19:38:54 +0200   15759 execution.flow     INFO     Node echo_my_prompt completes.\n",
      "[2024-04-25 19:38:54,747][flowinvoker][INFO] - Flow run result: {'output_prompt': 'neutre'}\n",
      "[2024-04-25 19:38:54,748][pfserving-app][INFO] - Flow does not enable streaming response.\n",
      "[2024-04-25 19:38:54,748][pfserving-app][INFO] - Finish monitoring request, request_id: None, client_request_id: None.\n",
      "INFO:werkzeug:127.0.0.1 - - [25/Apr/2024 19:38:54] \"POST /score HTTP/1.1\" 200 -\n",
      "[2024-04-25 19:39:08,825][pfserving-app][INFO] - Start monitoring new request, request_id: None, client_request_id: None\n",
      "[2024-04-25 19:39:08,825][pfserving-app][INFO] - Start loading request data...\n",
      "[2024-04-25 19:39:08,825][flowinvoker][INFO] - Validating flow input with data {'text': \"ne m'aimes-tu pas?\"}\n",
      "[2024-04-25 19:39:08,825][flowinvoker][INFO] - Execute flow with data {'text': \"ne m'aimes-tu pas?\"}\n",
      "2024-04-25 19:39:08 +0200   15759 execution.flow     INFO     Start executing nodes in thread pool mode.\n",
      "2024-04-25 19:39:08 +0200   15759 execution.flow     INFO     Start to run 2 nodes with concurrency level 16.\n",
      "2024-04-25 19:39:08 +0200   15759 execution.flow     INFO     Executing node hello_prompt. node run id: 893558a7-fb9a-4730-9fa6-49d00a1d1027_hello_prompt_c79abfe7-5fbe-4672-a254-bf88050d2b1c\n",
      "2024-04-25 19:39:08 +0200   15759 execution.flow     INFO     Node hello_prompt completes.\n",
      "2024-04-25 19:39:08 +0200   15759 execution.flow     INFO     Executing node echo_my_prompt. node run id: 893558a7-fb9a-4730-9fa6-49d00a1d1027_echo_my_prompt_c4f5a555-dcd3-4d7c-80c9-a2d0fba037a3\n",
      "2024-04-25 19:39:09 +0200   15759 execution.flow     INFO     Node echo_my_prompt completes.\n",
      "[2024-04-25 19:39:09,736][flowinvoker][INFO] - Flow run result: {'output_prompt': 'négatif'}\n",
      "[2024-04-25 19:39:09,736][pfserving-app][INFO] - Flow does not enable streaming response.\n",
      "[2024-04-25 19:39:09,736][pfserving-app][INFO] - Finish monitoring request, request_id: None, client_request_id: None.\n",
      "INFO:werkzeug:127.0.0.1 - - [25/Apr/2024 19:39:09] \"POST /score HTTP/1.1\" 200 -\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# N'exécuter que dans VS Code (au risque de bloquer les tests CI)\n",
    "if (len(sys.argv) == 2):\n",
    "    !pf flow serve --source $work_directory --port 8080 --host localhost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testez le serveur avec la commande suivante dans une fenêtre de terminal.\n",
    "\n",
    "```\n",
    "curl http://localhost:8080/score --data '{\"text\":\"Quelle belle voiture!\"}' -X POST  -H \"Content-Type: application/json\"\n",
    "```\n",
    "\n",
    "Pour \"chatter\" avec le serveur, naviguez à l'adresse http://localhost:8080.\n",
    "\n",
    "> <span style='color:red'>Pensez à stopper manuellement l'exécution de la cellule contenant la commande `pf flow serve`.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Déploiement en production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jlchereau/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jlchereau/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jlchereau/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "WARNING:root:'from promptflow import tool' is deprecated and will be removed in the future. Use 'from promptflow.core import tool' instead.\n",
      "WARNING:root:'from promptflow import ToolProvider' is deprecated and will be removed in the future. Use 'from promptflow.core import ToolProvider' instead.\n",
      "Exported flow to /Users/jlchereau/WebstormProjects/Digillia/Digillia-Colab/tools/promptflow/build.\n",
      "please check /Users/jlchereau/WebstormProjects/Digillia/Digillia-Colab/tools/promptflow/build/README.md for how to use it.\n"
     ]
    }
   ],
   "source": [
    "# Création d'un environnement docker pour `docker build`\n",
    "!pf flow build --source $work_directory --output $work_directory/build --format docker\n",
    "# !docker build -t $image_name $work_directory/build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ménage\n",
    "!rm -rf $work_directory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
